{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook with PCA model and no conditionning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#import external libraries\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths in git\n",
    "\n",
    "#root git folder \n",
    "#path_main_folder = '/home/marotant/dev/Autoencoder_Embedding_Expert_Caracteristion_'\n",
    "path_main_folder = '/home/jovyan'#specify the root folder of the git repo\n",
    "\n",
    "#add  to path root git folder \n",
    "sys.path.append(path_main_folder)\n",
    "#add  to path source code folder\n",
    "sys.path.append(path_main_folder+'/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import class and methods from src\n",
    "from keras import backend as K\n",
    "from CVAE.callbacks import NEpochLogger,callbackWeightLoss\n",
    "#from CVAE.cvae import compile_cvae, run_cvae\n",
    "from CVAE.cvae_model import CVAE, CVAE_emb, CAE\n",
    "from conso.load_shape_data import *  \n",
    "\n",
    "import Visualisation.buildProjector\n",
    "from Visualisation.buildProjector import *\n",
    "from FeaturesScore.scoring import *\n",
    "#from conso.load_shape_data import get_x_conso_autoencoder\n",
    "from conso.conso_helpers import plot_latent_space_projection, pyplot_latent_space_projection_temp, pyplot_latent_space_projection_error\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directories to store trained model and the related projector\n",
    "\n",
    "log_dir_projector=path_main_folder+\"/notebooks/logs/Expe1/PCA/projector\"\n",
    "log_dir_model=path_main_folder+\"/notebooks/logs/Expe1/PCA/model\"\n",
    "if not(os.path.isdir(log_dir_projector)):\n",
    "    os.makedirs(log_dir_projector)\n",
    "if not(os.path.isdir(log_dir_model)):\n",
    "    os.makedirs(log_dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents:\n",
    "- Load Data\n",
    "- Make Training Set\n",
    "- Define and Train Model\n",
    "- Build Projector\n",
    "- Compute Feature Scores in latent space\n",
    "- Study reconstruction Error\n",
    "- Study Holidays prediction\n",
    "- Detect atypical events\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "path_data = os.path.join(path_main_folder, 'data')\n",
    "dataset_csv = os.path.join(path_data, \"dataset.csv\")\n",
    "x_conso = pd.read_csv(dataset_csv, sep=\",\",)\n",
    "x_conso.ds = pd.to_datetime(x_conso.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#drop indices column\n",
    "x_conso=x_conso.drop(columns=x_conso.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize data frame head\n",
    "x_conso.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training set of daily electrical consumption profiles and conditions \n",
    "In this experiment there is no condition to pass. This is not something we can do with a PCA anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_set_plot = 'train'\n",
    "version = '-v1'\n",
    "nPoints=1830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_xconso = {'train': x_conso}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input variables\n",
    "type_scaler = 's'\n",
    "dict_xconso, _ = normalize_xconso(dict_xconso, type_scaler = 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset_autoencoder(dict_xconso=dict_xconso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_info = pd.DataFrame(dataset[name_set_plot]['ds'])\n",
    "calendar_info['month'] = calendar_info.ds.dt.month\n",
    "calendar_info['weekday'] = calendar_info.ds.dt.weekday\n",
    "calendar_info['is_weekday'] = (calendar_info.weekday < 5).apply(lambda x:int(x))\n",
    "calendar_info = pd.merge(calendar_info, x_conso[['ds', 'is_holiday_day']], on='ds', how ='left')\n",
    "calendar_info.loc[calendar_info['is_holiday_day'].isna(),'is_holiday_day'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and learn PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset['train']['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # import KFold\n",
    "import sklearn as sk\n",
    "kf = KFold(n_splits=5) # Define the split - into 2 folds \n",
    "kf.get_n_splits(x) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    #print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    principalComponents = pca.fit_transform(X_train)\n",
    "    X_test_pca=pca.transform(X_test)\n",
    "    x_hat = pca.inverse_transform(X_test_pca)\n",
    "    print(\"mae loss:\")\n",
    "    print(sk.metrics.mean_absolute_error(X_test,x_hat))\n",
    "    print(\"mse loss:\")\n",
    "    print(sk.metrics.mean_squared_error(X_test,x_hat))\n",
    "   # y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = log_dir_model+'/pca.sav'\n",
    "pickle.dump(pca, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_encoded=pca.transform(x)\n",
    "x_hat = pca.inverse_transform(x_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "print(\"mae loss:\")\n",
    "sk.metrics.mean_absolute_error(x,x_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the latent space with the construction of a tensorboard projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nPoints=1500 #if you want to visualize images of consumption profiles and its recontruction in tensorboard, there is a maximum size that can be handle for a sprite image. 1830 is  \n",
    "import os,cv2\n",
    "x_encoded_reduced=x_encoded[0:nPoints,]\n",
    "images=createLoadProfileImages(x,x_hat,nPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sprites=images_to_sprite(images)\n",
    "cv2.imwrite(os.path.join(log_dir_projector, 'sprite_4_classes.png'), sprites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writeMetaData(log_dir_projector,x_conso,calendar_info,nPoints,has_Odd=False)\n",
    "buildProjector(x_encoded_reduced,images=images, log_dir=log_dir_projector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir_projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Features in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noCond_PCA=predictFeaturesInLatentSPace(x_conso,calendar_info,x_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reconstruction error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=np.sum(np.abs((x - x_hat)),axis=1)/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a histogram over residuals\n",
    "import seaborn as sn\n",
    "sn.distplot(error, kde=False, fit=stats.norm, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the day with errors above a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorThreshold=0.15\n",
    "idxMaxError=[i for i in range(0,nPoints) if error[i]>=ErrorThreshold]\n",
    "calender_error=calendar_info.loc[idxMaxError]\n",
    "calender_error['error']=error[idxMaxError]\n",
    "\n",
    "calender_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first n days with highest errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDays=30\n",
    "\n",
    "decreasingOrderIdx=np.argsort(-error)\n",
    "calendar_Error_Highest=calendar_info.loc[decreasingOrderIdx[0:nDays]]\n",
    "calendar_Error_Highest['error']=error[decreasingOrderIdx[0:nDays]]\n",
    "calendar_Error_Highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the reconstruction error over a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice=1185 #1185 is the changing hour day end of march\n",
    "fig = plt.figure(dpi=100,figsize=(3,3))\n",
    "#set(gca,'Color','k')\n",
    "plt.plot(x[indice,:])\n",
    "plt.plot(x_hat[indice,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the reconstruction error over the days with highest error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPlots=10#len(idxMaxError)\n",
    "nCols=5\n",
    "nRows=int(nPlots/nCols)+1\n",
    "fig = plt.figure(dpi=100,figsize=(10,10))\n",
    "for i in range(1, nPlots):\n",
    "    plt.subplot(nRows, nCols, i)\n",
    "    fig.subplots_adjust(hspace=.5)\n",
    "    indice=decreasingOrderIdx[i-1]\n",
    "    plt.plot(x[indice,:])\n",
    "    plt.plot(x_hat[indice,:])\n",
    "    plt.title( calendar_Error_Highest.ds.dt.date.iloc[i-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of holiday predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation des features d'interet\n",
    "yHd=calendar_info['is_holiday_day'].astype(int)\n",
    "indicesHd=np.array([i for i in range(0, nPoints) if yHd[i] == 1])\n",
    "yHd_only=yHd[yHd==1]\n",
    "x_encoded_Hd=x_encoded[indicesHd,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "results_hd=scoreKnnResults(x_encoded,yHd,type='classifier',k=5,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## holidays well predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hd_only=[results_hd['predP'][i] for i in indicesHd ]\n",
    "indices_Hd_predict=[i for i in indicesHd if  results_hd['predP'][i]>=0.5]\n",
    "indices_Hd_not_predicted=[i for i in indicesHd if  results_hd['predP'][i]<0.5]\n",
    "calendar_info.loc[indices_Hd_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "yWeekday=calendar_info['is_weekday']\n",
    "results_wk=scoreKnnResults(x_encoded,yWeekday,type='classifier',k=10,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays_predicted_as_weekend=[i for i in range(0,1830) if  results_wk['predP'][i]<=0.5 and yWeekday[i]==1]\n",
    "calendar_info.loc[weekdays_predicted_as_weekend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weekdays_predicted_as_weekend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find out that holidays actually look alike weekends even if they are happening during weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holidays & nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(10)\n",
    "neigh.fit(x_encoded)\n",
    "\n",
    "[distance_knn,kneighbors]=neigh.kneighbors(x_encoded, 2, return_distance=True)\n",
    "nearest=distance_knn[:,1]\n",
    "fig = plt.figure(dpi=100,figsize=(3,3))\n",
    "plt.hist(nearest,bins=100)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.describe(nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100,figsize=(3,3))\n",
    "plt.hist(nearest[indicesHd],bins=100)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(nearest[indicesHd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_info.loc[np.where(nearest>=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2013-01-19 and 2017-01-21 were big snowy events in France. 2013-03-03 and 2014-12-01 are harder to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicesNear=[i for i in range(0,len(nearest)) if nearest[i]>=1]\n",
    "nearest[np.where(nearest>=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPlots=len(indicesNear)#len(idxMaxError)\n",
    "nCols=5\n",
    "nRows=int(nPlots/nCols)+1\n",
    "fig = plt.figure(dpi=100,figsize=(10,3))\n",
    "for i in range(1, nPlots+1):\n",
    "    plt.subplot(nRows, nCols, i)\n",
    "    fig.subplots_adjust(hspace=.5)\n",
    "    indice=indicesNear[i-1]\n",
    "    plt.plot(x[indice,:])\n",
    "    plt.plot(x_hat[indice,:])\n",
    "    plt.title( calendar_info.ds.dt.date.iloc[indice])\n",
    "fig.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "- 3 dimensions covers most of the information for the variety of daily load curves \n",
    "- We recovered with this simple linear model the two main features that caracterizes electrical consumption: weekday and temperature\n",
    "- Holidays are not yet well predicted and represented, although we know they are an important atypical factor.\n",
    "- We however detect that holidays all look alike weekend days\n",
    "- We discover some first interpretable events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
